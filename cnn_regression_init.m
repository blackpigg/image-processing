function net = cnn_regression_init(varargin)
%==========================================================================
inputsize = 39;

% CNN_MNIST_LENET Initialize a CNN similar for MNIST
opts.batchNormalization = true;
opts.networkType        = 'simplenn';
opts                    = vl_argparse(opts, varargin);

% control random number generation (shuffling method and its seed)
rng('default'); rng(0)

% 네트워크 정의
f = 1/100;
net.layers = {};
net.layers{end+1} = struct(...
    'type','conv',...
    'weights', {{f*randn(4, 4, 1, 20, 'single'), zeros(1, 20,'single')}},...
    'stride', 1, ...
    'pad',0);

net.layers{end+1} = struct(...
    'type', 'relu');

net.layers{end+1} = struct(...
    'type','pool',...
    'method', 'max',...
    'pool',[2,2],...
    'stride', 2, ...
    'pad',0);

net.layers{end+1} = struct(...
    'type','conv',...
    'weights', {{f*randn(3, 3, 20, 40, 'single'), zeros(1, 40,'single')}},...
    'stride', 1, ...
    'pad',0);

net.layers{end+1} = struct(...
    'type', 'relu');

net.layers{end+1} = struct(...
    'type','pool',...
    'method', 'max',...
    'pool',[2,2],...
    'stride', 2, ...
    'pad',0);

net.layers{end+1} = struct(...
    'type','conv',...
    'weights', {{f*randn(3, 3, 40, 60, 'single'), zeros(1, 60,'single')}},...
    'stride', 1, ...
    'pad',0);

net.layers{end+1} = struct(...
    'type', 'relu');

net.layers{end+1} = struct(...
    'type','pool',...
    'method', 'max',...
    'pool',[2,2],...
    'stride', 2, ...
    'pad',0);


net.layers{end+1} = struct(...
    'type','conv',...
    'weights', {{f*randn(2, 2, 60, 80, 'single'), zeros(1, 80,'single')}},...
    'stride', 1, ...
    'pad',0);

net.layers{end+1} = struct(...
    'type', 'relu');

net.layers{end+1} = struct(...
    'type','conv',...
    'weights', {{f*randn(2, 2, 80, 120, 'single'), zeros(1, 120,'single')}},...
    'stride', 1, ...
    'pad',0);

net.layers{end+1} = struct(...
    'type','conv',...
    'weights', {{f*randn(1, 1, 120, 10, 'single'), zeros(1, 10,'single')}},...
    'stride', 1, ...
    'pad',0);
net.layers{end+1} = struct(...
    'type', 'nnL2');
% 



% TODO: Meta parameters

net.meta.inputSize              = [inputsize inputsize 1];
net.meta.trainOpts.learningRate = 0.001;
net.meta.trainOpts.numEpochs    = 20;
net.meta.trainOpts.batchSize    = 100;

% Fill in defaul values
net = vl_simplenn_tidy(net);

% network type 대응: DagNN로 구조 변경
% switch lower(opts.networkType)
%     case 'simplenn'
%         % done
%     case 'dagnn'
%         net = dagnn.DagNN.fromSimpleNN(net, 'canonicalNames', true);
%         net.addLayer(...
%             'top1err', dagnn.Loss('loss', 'classerror'), ...
%             {'prediction', 'label'}, 'error');
%         net.addLayer(...
%             'top5err', dagnn.Loss('loss', 'topkerror', ...
%             'opts', {'topk', 5}), {'prediction', 'label'}, 'top5err');
%     otherwise
%         assert(false);
% end
end